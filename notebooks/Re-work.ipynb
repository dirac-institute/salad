{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12528b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect\n",
    "# project\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea987fff-3bd9-4b54-8808-c9a3ce09afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 11 14:33:38 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:21:00.0  On |                  N/A |\n",
      "| 28%   36C    P8              21W / 260W |   7587MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:48:00.0 Off |                  N/A |\n",
      "| 25%   29C    P8              14W / 260W |   1460MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2352      G   /usr/bin/X                                   39MiB |\n",
      "|    0   N/A  N/A      2977      G   /usr/bin/gnome-shell                         14MiB |\n",
      "|    0   N/A  N/A     25304      C   python                                      710MiB |\n",
      "|    0   N/A  N/A     91601      C   .../miniconda3/envs/booknlp/bin/python     6818MiB |\n",
      "|    1   N/A  N/A     91601      C   .../miniconda3/envs/booknlp/bin/python     1456MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cc6ddd-e1ad-49e6-9723-d6c34de17e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8fc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from salad.serialize import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af769a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = read(\"/epyc/projects/salad/search/tno_search/DEEP/20190403/A0c/detector_3/snr_5.0/regular/catalog.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5450da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = detections.X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568cb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directions\n",
    "from salad.directions import SearchDirections\n",
    "import astropy.units as u\n",
    "\n",
    "dx = 7.98314077571659 * u.arcsec\n",
    "dt = (X[:, 2].max() - X[:, 2].min())*u.day\n",
    "ref_time = X[:, 2].min()\n",
    "directions = SearchDirections([0.1 * u.deg/u.day, 0.5 * u.deg/u.day], [0 * u.deg, 359 * u.deg], dx, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7eaf6f4-08d2-4b0a-89a3-462f88d89fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9118, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5bb91b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directions.b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4c4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project\n",
    "import numba\n",
    "from numba import cuda\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "@numba.njit()\n",
    "def project_xyz(x: np.float64, y: np.float64, t: np.float64, vx: np.float64, vy: np.float64, reference_time: np.float64):\n",
    "    x_prime = x - vx * (t - reference_time)\n",
    "    y_prime = y - vy * (t - reference_time)\n",
    "    return x_prime, y_prime\n",
    "\n",
    "@numba.njit()\n",
    "def digitize_point(x, y, min_x, min_y, dx, dy):\n",
    "    return int((x - min_x)/dx), int((y - min_y)/dy)\n",
    "\n",
    "# @numba.njit(parallel=True)\n",
    "def vote_points_cpu_mask(hough: np.ndarray, X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time, coef, results):\n",
    "    \"\"\"\n",
    "    Given detections vote in the hough space\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    for j in range(results.shape[0]):\n",
    "                        mask_dir = results[j, 0]\n",
    "                        mask_x = results[j, 1]\n",
    "                        mask_y = results[j, 2]\n",
    "                        print(mask_dir, mask_x, mask_y)\n",
    "                        if dir_idx == mask_dir and x_idx == mask_x and y_idx == mask_y:\n",
    "                            hough[dir_idx, x_idx, y_idx] += coef\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def vote_points_cpu(hough: np.ndarray, X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time, coef: np.float64=1):\n",
    "    \"\"\"\n",
    "    Given detections vote in the hough space\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    hough[dir_idx, x_idx, y_idx] += coef\n",
    "\n",
    "@cuda.jit\n",
    "def _vote_points_gpu(hough, X, directions, x_min, y_min, dx, dy, reference_time, coef):\n",
    "    \"\"\"\n",
    "    GPU version of vote_points using CUDA parallelism.\n",
    "    Each thread processes one (dir_idx, point_idx) pair.\n",
    "    \"\"\"\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    point_idx = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "\n",
    "    num_dir, n = directions.shape[0], X.shape[0]\n",
    "\n",
    "    if dir_idx >= num_dir or point_idx >= n:\n",
    "        return  # Out-of-bounds check\n",
    "\n",
    "    direction = directions[dir_idx]\n",
    "    p = X[point_idx]\n",
    "    x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "    x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "\n",
    "    if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "        cuda.atomic.add(hough, (dir_idx, x_idx, y_idx), coef)  # Atomic update to avoid race conditions\n",
    "        \n",
    "@cuda.jit\n",
    "def _vote_points_gpu_mask(hough, X, directions, x_min, y_min, dx, dy, reference_time, coef, mask_dir, mask_x, mask_y):\n",
    "    \"\"\"\n",
    "    GPU version of vote_points using CUDA parallelism.\n",
    "    Each thread processes one (dir_idx, point_idx) pair.\n",
    "    \"\"\"\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    point_idx = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "\n",
    "    num_dir, n = directions.shape[0], X.shape[0]\n",
    "\n",
    "    if dir_idx >= num_dir or point_idx >= n:\n",
    "        return  # Out-of-bounds check\n",
    "\n",
    "    direction = directions[dir_idx]\n",
    "    p = X[point_idx]\n",
    "    x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "    x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "\n",
    "    if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "        if dir_idx == mask_dir and x_idx == mask_x and y_idx == mask_y:\n",
    "            cuda.atomic.add(hough, (dir_idx, x_idx, y_idx), coef)  # Atomic update to avoid race conditions\n",
    "\n",
    "def vote_points_gpu(hough: np.ndarray, X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time, coef: np.float64 = 1, mask_dir=-1, mask_x=-1, mask_y=-1):\n",
    "    \"\"\"\n",
    "    Host function to launch the GPU kernel.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "\n",
    "    # Transfer data to GPU\n",
    "    d_hough = cuda.to_device(hough)\n",
    "    d_X = cuda.to_device(X)\n",
    "    d_directions = cuda.to_device(directions)\n",
    "\n",
    "    # Configure GPU threads and blocks\n",
    "    threads_per_block = (16, 16)  # Tunable parameters\n",
    "    blocks_per_grid = ((num_dir + threads_per_block[0] - 1) // threads_per_block[0], \n",
    "                       (n + threads_per_block[1] - 1) // threads_per_block[1])\n",
    "\n",
    "    # Launch the CUDA kernel\n",
    "    if mask_dir != -1 and mask_x != -1 and mask_y != -1:\n",
    "        _vote_points_gpu_mask[blocks_per_grid, threads_per_block](\n",
    "            d_hough, d_X, d_directions, x_min, y_min, dx, dy, reference_time, coef, mask_dir, mask_x, mask_y\n",
    "        )\n",
    "    else:\n",
    "        _vote_points_gpu[blocks_per_grid, threads_per_block](\n",
    "            d_hough, d_X, d_directions, x_min, y_min, dx, dy, reference_time, coef\n",
    "        )\n",
    "\n",
    "    # Copy back the updated Hough space\n",
    "    return d_hough.copy_to_host()\n",
    "\n",
    "    \n",
    "@numba.njit(parallel=True)\n",
    "def projected_bounds_cpu(X: np.ndarray, directions: np.ndarray, reference_time: np.float64):\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    min_x_arr = np.full(num_dir, np.inf)\n",
    "    max_x_arr = np.full(num_dir, -np.inf)\n",
    "    min_y_arr = np.full(num_dir, np.inf)\n",
    "    max_y_arr = np.full(num_dir, -np.inf)\n",
    "    \n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                min_x_arr[dir_idx] = min(min_x_arr[dir_idx], x_prime)\n",
    "                max_x_arr[dir_idx] = max(max_x_arr[dir_idx], x_prime)\n",
    "                min_y_arr[dir_idx] = min(min_y_arr[dir_idx], y_prime)\n",
    "                max_y_arr[dir_idx] = max(max_y_arr[dir_idx], y_prime)\n",
    "\n",
    "    min_x = np.min(min_x_arr)\n",
    "    max_x = np.max(max_x_arr)\n",
    "    min_y = np.min(min_y_arr)\n",
    "    max_y = np.max(max_y_arr)\n",
    "    \n",
    "    return min_x, max_x, min_y, max_y\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def _projected_bounds_gpu(X, directions, reference_time, min_x_arr, max_x_arr, min_y_arr, max_y_arr):\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    \n",
    "    if dir_idx >= num_dir:\n",
    "        return\n",
    "\n",
    "    direction = directions[dir_idx]\n",
    "    \n",
    "    # Initialize local min/max\n",
    "    min_x = np.inf\n",
    "    max_x = -np.inf\n",
    "    min_y = np.inf\n",
    "    max_y = -np.inf\n",
    "\n",
    "    # Iterate over all points\n",
    "    for i in range(n):\n",
    "        p = X[i]\n",
    "        x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "        min_x = min(min_x, x_prime)\n",
    "        max_x = max(max_x, x_prime)\n",
    "        min_y = min(min_y, y_prime)\n",
    "        max_y = max(max_y, y_prime)\n",
    "\n",
    "    # Store results in global memory\n",
    "    min_x_arr[dir_idx] = min_x\n",
    "    max_x_arr[dir_idx] = max_x\n",
    "    min_y_arr[dir_idx] = min_y\n",
    "    max_y_arr[dir_idx] = max_y\n",
    "    \n",
    "def projected_bounds_gpu(X: np.ndarray, directions: np.ndarray, reference_time: np.float64):\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "\n",
    "    # Allocate device arrays\n",
    "    d_X = cuda.to_device(X)\n",
    "    d_directions = cuda.to_device(directions)\n",
    "    d_min_x_arr = cuda.device_array(num_dir, dtype=np.float64)\n",
    "    d_max_x_arr = cuda.device_array(num_dir, dtype=np.float64)\n",
    "    d_min_y_arr = cuda.device_array(num_dir, dtype=np.float64)\n",
    "    d_max_y_arr = cuda.device_array(num_dir, dtype=np.float64)\n",
    "\n",
    "    # Define CUDA thread/block config\n",
    "    threads_per_block = 128\n",
    "    blocks_per_grid = (num_dir + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    # Launch kernel\n",
    "    _projected_bounds_gpu[blocks_per_grid, threads_per_block](\n",
    "        d_X, d_directions, reference_time, d_min_x_arr, d_max_x_arr, d_min_y_arr, d_max_y_arr\n",
    "    )\n",
    "\n",
    "    # Copy results back to host\n",
    "    min_x_arr = d_min_x_arr.copy_to_host()\n",
    "    max_x_arr = d_max_x_arr.copy_to_host()\n",
    "    min_y_arr = d_min_y_arr.copy_to_host()\n",
    "    max_y_arr = d_max_y_arr.copy_to_host()\n",
    "\n",
    "    # Final reduction on CPU\n",
    "    min_x = np.min(min_x_arr)\n",
    "    max_x = np.max(max_x_arr)\n",
    "    min_y = np.min(min_y_arr)\n",
    "    max_y = np.max(max_y_arr)\n",
    "\n",
    "    return min_x, max_x, min_y, max_y\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def hough_argmax_cpu(hough: np.ndarray):\n",
    "    \"\"\"\n",
    "    Finds the location of the maximum value in the Hough space using parallel execution.\n",
    "    \"\"\"\n",
    "    num_dir, x_dim, y_dim = hough.shape\n",
    "    max_vals = np.full(num_dir, -np.inf)  # Per-direction max values\n",
    "    max_indices = np.full((num_dir, 3), -1, dtype=np.int32)  # Store (dir_idx, x_idx, y_idx)\n",
    "\n",
    "    # Parallel over directions\n",
    "    for dir_idx in numba.prange(num_dir):\n",
    "        local_max = -np.inf\n",
    "        local_x_idx = -1\n",
    "        local_y_idx = -1\n",
    "\n",
    "        for x_idx in range(x_dim):\n",
    "            for y_idx in range(y_dim):\n",
    "                if hough[dir_idx, x_idx, y_idx] > local_max:\n",
    "                    local_max = hough[dir_idx, x_idx, y_idx]\n",
    "                    local_x_idx = x_idx\n",
    "                    local_y_idx = y_idx\n",
    "\n",
    "        # Store per-thread results\n",
    "        max_vals[dir_idx] = local_max\n",
    "        max_indices[dir_idx, 0] = dir_idx\n",
    "        max_indices[dir_idx, 1] = local_x_idx\n",
    "        max_indices[dir_idx, 2] = local_y_idx\n",
    "\n",
    "    # Final reduction: Find the overall max from the per-direction max values\n",
    "    global_max = -np.inf\n",
    "    global_max_idx = np.array([-1, -1, -1], dtype=np.int32)\n",
    "\n",
    "    for i in range(num_dir):\n",
    "        if max_vals[i] > global_max:\n",
    "            global_max = max_vals[i]\n",
    "            global_max_idx[0] = max_indices[i, 0]\n",
    "            global_max_idx[1] = max_indices[i, 1]\n",
    "            global_max_idx[2] = max_indices[i, 2]\n",
    "\n",
    "    return global_max_idx, global_max\n",
    "\n",
    "@cuda.jit\n",
    "def _hough_argmax_gpu(hough, max_idx, max_val):\n",
    "    \"\"\"\n",
    "    CUDA kernel to find the max value and its index in the Hough space.\n",
    "    Uses shared memory and block-wide reduction.\n",
    "    \"\"\"\n",
    "    # Thread IDs\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    x_idx = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    y_idx = cuda.blockIdx.z * cuda.blockDim.z + cuda.threadIdx.z\n",
    "\n",
    "    # Shared memory for per-block reduction\n",
    "    shared_max_val = cuda.shared.array(shape=(1,), dtype=numba.float64)\n",
    "    shared_max_idx = cuda.shared.array(shape=(3,), dtype=numba.int32)\n",
    "\n",
    "    # Initialize shared memory\n",
    "    if cuda.threadIdx.x == 0 and cuda.threadIdx.y == 0 and cuda.threadIdx.z == 0:\n",
    "        shared_max_val[0] = -np.inf\n",
    "        shared_max_idx[0] = -1  # dir_idx\n",
    "        shared_max_idx[1] = -1  # x_idx\n",
    "        shared_max_idx[2] = -1  # y_idx\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Ensure within bounds\n",
    "    if dir_idx >= hough.shape[0] or x_idx >= hough.shape[1] or y_idx >= hough.shape[2]:\n",
    "        return\n",
    "\n",
    "    val = hough[dir_idx, x_idx, y_idx]\n",
    "\n",
    "    # Block-wide reduction to find max value\n",
    "    cuda.syncthreads()\n",
    "    if val > shared_max_val[0]:  \n",
    "        shared_max_val[0] = val\n",
    "        shared_max_idx[0] = dir_idx\n",
    "        shared_max_idx[1] = x_idx\n",
    "        shared_max_idx[2] = y_idx\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Only one thread writes to global memory\n",
    "    if cuda.threadIdx.x == 0 and cuda.threadIdx.y == 0 and cuda.threadIdx.z == 0:\n",
    "        cuda.atomic.max(max_val, 0, shared_max_val[0])\n",
    "        if shared_max_val[0] == max_val[0]:  # Ensure atomicity\n",
    "            max_idx[0] = shared_max_idx[0]\n",
    "            max_idx[1] = shared_max_idx[1]\n",
    "            max_idx[2] = shared_max_idx[2]\n",
    "\n",
    "def hough_argmax_gpu(hough: np.ndarray):\n",
    "    \"\"\"\n",
    "    Wrapper function to execute the CUDA kernel and return the max location.\n",
    "    \"\"\"\n",
    "    d_hough = cuda.to_device(hough)\n",
    "    d_max_idx = cuda.device_array(3, dtype=np.int32)\n",
    "    d_max_val = cuda.device_array(1, dtype=np.float64)\n",
    "\n",
    "    threads_per_block = (8, 8, 8)  # Tunable parameter\n",
    "    blocks_per_grid = (\n",
    "        (hough.shape[0] + threads_per_block[0] - 1) // threads_per_block[0],\n",
    "        (hough.shape[1] + threads_per_block[1] - 1) // threads_per_block[1],\n",
    "        (hough.shape[2] + threads_per_block[2] - 1) // threads_per_block[2],\n",
    "    )\n",
    "\n",
    "    # Launch kernel\n",
    "    _hough_argmax_gpu[blocks_per_grid, threads_per_block](d_hough, d_max_idx, d_max_val)\n",
    "\n",
    "    # Copy results back\n",
    "    max_idx = d_max_idx.copy_to_host()\n",
    "    max_val = d_max_val.copy_to_host()\n",
    "\n",
    "    return tuple(max_idx), max_val[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e974ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 38 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7 ms ± 319 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "min_x, max_x, min_y, max_y = projected_bounds_gpu(X, directions.b, ref_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ee3868-b73e-482f-8927-8128026efa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.9 ms ± 66.5 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "min_x, max_x, min_y, max_y = projected_bounds_cpu(X, directions.b, ref_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941aea03-fd28-4461-aa4c-bfdc0c38b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.53093121715725 217.00136276871302 -11.222229046885362 -10.911972249328436\n"
     ]
    }
   ],
   "source": [
    "min_x, max_x, min_y, max_y = projected_bounds_gpu(X, directions.b, ref_time)\n",
    "print(min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5c01a3-0bd1-46af-bf7c-45d57e4fb16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.53093121715725 217.00136276871302 -11.222229046885362 -10.911972249328436\n"
     ]
    }
   ],
   "source": [
    "min_x, max_x, min_y, max_y = projected_bounds_cpu(X, directions.b, ref_time)\n",
    "print(min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fef32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x, max_x, min_y, max_y = projected_bounds_gpu(X, directions.b, ref_time)\n",
    "\n",
    "num_dir = directions.b.shape[0]\n",
    "_dx = dx.to(u.deg).value\n",
    "_dy = _dx\n",
    "num_x = int((max_x - min_x) / _dx  + 1)\n",
    "num_y = int((max_y - min_y) / _dy  + 1)\n",
    "\n",
    "hough = np.zeros((num_dir, num_x, num_y), dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5cdb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 213, 140)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vote_points()\n",
    "hough.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204daff7-40ed-4dd3-b90a-b3ab6baae9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 207 ms, sys: 75.8 ms, total: 283 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hough2 = vote_points_gpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2abd53e-be7d-43b4-a23e-dae04f1485a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 751 ms, sys: 40.1 ms, total: 791 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vote_points_cpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0214e441-90b7-4ca2-a228-08faa067398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hough2 == hough).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c16d565-5b3e-4e59-b040-7e35e0dee85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def _hough_max_gpu(result, hough):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    bdim = cuda.blockDim.x\n",
    "    i = (bid * bdim) + tid\n",
    "    \n",
    "    if i >= hough.shape[0]:\n",
    "        return\n",
    "    \n",
    "    y = -1\n",
    "    z = -1\n",
    "    v = -np.inf\n",
    "    for j in range(hough.shape[1]):\n",
    "        for k in range(hough.shape[2]):\n",
    "            val = hough[i, j, k]\n",
    "            if val > v:\n",
    "                v = val\n",
    "                y = j\n",
    "                z = k\n",
    "    \n",
    "    result[i][0] = y\n",
    "    result[i][1] = z\n",
    "    result[i][2] = v\n",
    "\n",
    "def hough_max_gpu(hough):\n",
    "    result = np.zeros((hough.shape[0], 3), dtype=np.int32)\n",
    "    _hough_max_gpu[512, hough.shape[0] // 512 + 1](result, hough)\n",
    "    i = result[:, 2].argmax()\n",
    "    j = result[i, 0]\n",
    "    k = result[i, 1]\n",
    "    v = result[i, 2]\n",
    "    return (i, j, k), v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e9b91aa-a18c-449c-ab29-8effc44feed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085, 155, 79) 101\n",
      "(2580, 130, 64) 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "h = hough.copy()\n",
    "idx, val = hough_max_gpu(h)\n",
    "print(idx, val)\n",
    "h = vote_points_gpu(\n",
    "    h, X, directions.b, min_x, min_y, _dx, _dy, ref_time, \n",
    "    coef=-1, mask_dir=idx[0], mask_x=idx[1], mask_y=idx[2]\n",
    ")\n",
    "idx, val = hough_max_gpu(h)\n",
    "print(idx, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a4efd8e0-8f45-4a38-857d-aa0e8943f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I actually need to loop through the results and mask over all of those values...\n",
    "def find_clusters_gpu(hough, n=10):\n",
    "    h = hough.copy()\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        idx, val = hough_max_gpu(h)\n",
    "        h = vote_points_gpu(\n",
    "            h, X, directions.b, min_x, min_y, _dx, _dy, ref_time, \n",
    "            coef=-1, mask_dir=idx[0], mask_x=idx[1], mask_y=idx[2]\n",
    "        )\n",
    "        results.append((idx, val))\n",
    "    return results\n",
    "\n",
    "def search_gpu(X, directions, dx, reference_time, num_results=10):\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    x_min, x_max, y_min, y_max = projected_bounds_gpu(X, directions.b, reference_time)\n",
    "    \n",
    "    num_dir = directions.b.shape[0]\n",
    "    _dx = dx.to(u.deg).value\n",
    "    _dy = _dx\n",
    "    num_x = int((x_max - x_min) / _dx  + 1)\n",
    "    num_y = int((y_max - y_min) / _dy  + 1)\n",
    "\n",
    "    hough = np.zeros((num_dir, num_x, num_y), dtype=np.uint32)    \n",
    "\n",
    "    num_dir, num_x, num_y = hough.shape\n",
    "    \n",
    "    h = hough.copy()\n",
    "    \n",
    "    d_hough = cuda.to_device(hough)\n",
    "    d_X = cuda.to_device(X)\n",
    "    d_directions = cuda.to_device(directions.b)\n",
    "    d_max = cuda.to_device(np.zeros((hough.shape[0], 3), dtype=np.int32))\n",
    "    d_results = cuda.to_device(np.zeros((num_results, 4), dtype=np.int32))\n",
    "\n",
    "    def _vote(coef=1, mask_dir=-1, mask_x=-1, mask_y=-1):\n",
    "        # Configure GPU threads and blocks\n",
    "        threads_per_block = (16, 16)  # Tunable parameters\n",
    "        blocks_per_grid = ((num_dir + threads_per_block[0] - 1) // threads_per_block[0], \n",
    "                           (n + threads_per_block[1] - 1) // threads_per_block[1])\n",
    "\n",
    "        # Launch the CUDA kernel\n",
    "        if mask_dir != -1 and mask_x != -1 and mask_y != -1:\n",
    "            _vote_points_gpu_mask[blocks_per_grid, threads_per_block](\n",
    "                d_hough, d_X, d_directions, x_min, y_min, _dx, _dy, reference_time, coef, mask_dir, mask_x, mask_y\n",
    "            )\n",
    "        else:\n",
    "            _vote_points_gpu[blocks_per_grid, threads_per_block](\n",
    "                d_hough, d_X, d_directions, x_min, y_min, _dx, _dy, reference_time, coef\n",
    "            )\n",
    "    \n",
    "    def _max():\n",
    "        _hough_max_gpu[256, num_dir // 256 + 1](d_max, d_hough)\n",
    "        \n",
    "        \n",
    "    _vote()\n",
    "    # results = [] # cuda device array\n",
    "    for n_i in range(num_results):\n",
    "        _max()\n",
    "        i = -1\n",
    "        v = -np.inf\n",
    "        for _ in range(len(d_max)):\n",
    "            if d_max[_, 2] > v:\n",
    "                v = d_max[_, 2]\n",
    "                i = _\n",
    "        j = d_max[i, 0]\n",
    "        k = d_max[i, 1]\n",
    "        d_results[n_i, 0] = i\n",
    "        d_results[n_i, 1] = j\n",
    "        d_results[n_i, 2] = k\n",
    "        d_results[n_i, 3] = v\n",
    "        print(\"cluster has value\", v, \"at\", (i, j, k))\n",
    "        _vote(coef=-1, mask_dir=i, mask_x=j, mask_y=k)\n",
    "    \n",
    "    return d_results.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "147e6802-cc05-4321-8e6b-d6de788cef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.16620738e+02, -1.10195710e+01,  5.85773073e+04,\n",
       "         8.45925000e+05],\n",
       "       [ 2.16620614e+02, -1.10503847e+01,  5.85773073e+04,\n",
       "         8.45925000e+05],\n",
       "       [ 2.16624234e+02, -1.10681670e+01,  5.85773073e+04,\n",
       "         8.45925000e+05],\n",
       "       ...,\n",
       "       [ 2.16879090e+02, -1.10967022e+01,  5.85773227e+04,\n",
       "         8.45934000e+05],\n",
       "       [ 2.16884674e+02, -1.11136933e+01,  5.85773227e+04,\n",
       "         8.45934000e+05],\n",
       "       [ 2.16912418e+02, -1.10304324e+01,  5.85773227e+04,\n",
       "         8.45934000e+05]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "87841eda-fd6b-4df7-82fc-3526fbde5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster has value 101 at (2085, 155, 79)\n",
      "cluster has value 99 at (2580, 130, 64)\n",
      "cluster has value 99 at (2710, 171, 50)\n",
      "cluster has value 99 at (2712, 70, 95)\n",
      "cluster has value 97 at (2644, 171, 50)\n",
      "cluster has value 96 at (2778, 146, 68)\n",
      "cluster has value 94 at (2645, 86, 88)\n",
      "cluster has value 91 at (2578, 139, 96)\n",
      "cluster has value 90 at (2456, 151, 60)\n",
      "cluster has value 90 at (2579, 139, 96)\n",
      "cluster has value 90 at (2847, 146, 68)\n",
      "cluster has value 84 at (2642, 136, 67)\n",
      "cluster has value 84 at (2646, 70, 96)\n",
      "cluster has value 83 at (2577, 136, 67)\n",
      "cluster has value 83 at (2644, 87, 88)\n",
      "cluster has value 82 at (2643, 139, 96)\n",
      "cluster has value 82 at (2644, 139, 96)\n",
      "cluster has value 81 at (2646, 86, 88)\n",
      "cluster has value 80 at (2641, 136, 67)\n",
      "cluster has value 79 at (2576, 136, 67)\n",
      "CPU times: user 4.22 s, sys: 743 ms, total: 4.96 s\n",
      "Wall time: 4.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2085,  155,   79,  101],\n",
       "       [2580,  130,   64,   99],\n",
       "       [2710,  171,   50,   99],\n",
       "       [2712,   70,   95,   99],\n",
       "       [2644,  171,   50,   97],\n",
       "       [2778,  146,   68,   96],\n",
       "       [2645,   86,   88,   94],\n",
       "       [2578,  139,   96,   91],\n",
       "       [2456,  151,   60,   90],\n",
       "       [2579,  139,   96,   90],\n",
       "       [2847,  146,   68,   90],\n",
       "       [2642,  136,   67,   84],\n",
       "       [2646,   70,   96,   84],\n",
       "       [2577,  136,   67,   83],\n",
       "       [2644,   87,   88,   83],\n",
       "       [2643,  139,   96,   82],\n",
       "       [2644,  139,   96,   82],\n",
       "       [2646,   86,   88,   81],\n",
       "       [2641,  136,   67,   80],\n",
       "       [2576,  136,   67,   79]], dtype=int32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search_gpu(X, directions, 7.98314077571659*u.arcsec, ref_time, num_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b11f1af4-554a-4064-aad1-729aedb88332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "def hough_max_cpu(hough):\n",
    "    idx = np.unravel_index(hough.argmax(), hough.shape)\n",
    "    return idx, hough[idx]\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def make_bins_cpu(X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time):\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    bins = np.full((num_dir, n, 2), -1)\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "                bins[dir_idx, i, 0] = x_idx\n",
    "                bins[dir_idx, i, 1] = y_idx\n",
    "    return bins\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def vote_points_cpu(hough: np.ndarray, X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time, coef):\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    hough[dir_idx, x_idx, y_idx] += coef\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def vote_bins_cpu(hough: np.ndarray, bins: np.ndarray, directions: np.ndarray, coef):\n",
    "    _, n, d = bins.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                x_idx = bins[dir_idx, i, 0]\n",
    "                y_idx = bins[dir_idx, i, 1]\n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    hough[dir_idx, x_idx, y_idx] += coef\n",
    "    \n",
    "@numba.njit(parallel=True)\n",
    "def find_voters_bins_cpu(hough: np.ndarray, bins: np.ndarray, directions: np.ndarray, mask_dir, mask_x, mask_y):\n",
    "    _, n, d = bins.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    \n",
    "    mask = np.full((num_dir, n), False)\n",
    "    _mask = np.full(n, False)\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                x_idx = bins[dir_idx, i, 0]\n",
    "                y_idx = bins[dir_idx, i, 1]                \n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    if dir_idx == mask_dir and x_idx == mask_x and y_idx == mask_y:\n",
    "                        mask[dir_idx, i] = True\n",
    "    for i in range(n):\n",
    "        for dir_idx in range(num_dir):\n",
    "            _mask[i] |= mask[dir_idx, i]\n",
    "            \n",
    "    return _mask\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def find_voters_points_cpu(hough: np.ndarray, X: np.ndarray, directions: np.ndarray, x_min, y_min, dx, dy, reference_time, mask_dir, mask_x, mask_y):\n",
    "    n, d = X.shape\n",
    "    num_dir = directions.shape[0]\n",
    "    \n",
    "    mask = np.full((num_dir, n), False)\n",
    "    _mask = np.full(n, False)\n",
    "    for dir_idx in numba.prange(num_dir): # for each direction\n",
    "        if dir_idx < num_dir:\n",
    "            direction = directions[dir_idx]\n",
    "            for i in range(n): # for each point\n",
    "                p = X[i]\n",
    "                x_prime, y_prime = project_xyz(p[0], p[1], p[2], direction[0], direction[1], reference_time)\n",
    "                x_idx, y_idx = digitize_point(x_prime, y_prime, x_min, y_min, dx, dy)\n",
    "                if 0 <= x_idx < hough.shape[1] and 0 <= y_idx < hough.shape[2]:\n",
    "                    if dir_idx == mask_dir and x_idx == mask_x and y_idx == mask_y:\n",
    "                        mask[dir_idx, i] = True\n",
    "    for i in range(n):\n",
    "        for dir_idx in range(num_dir):\n",
    "            _mask[i] |= mask[dir_idx, i]\n",
    "            \n",
    "    return _mask\n",
    "\n",
    "def find_clusters_points_cpu(X, hough, n=10):\n",
    "    results = np.full((n, 4), -1)\n",
    "    include = np.full(X.shape[0], True)\n",
    "    for i in range(n):\n",
    "        idx, val = hough_max_cpu(hough)\n",
    "        print(\"cluster has value\", val, \"at\", idx)\n",
    "        voters = find_voters_points_cpu(\n",
    "            hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time, *idx\n",
    "        )\n",
    "        vote_points_cpu(\n",
    "            hough, X[include & voters], directions.b, min_x, min_y, _dx, _dy, ref_time, -1\n",
    "        )\n",
    "        include &= ~voters # exclude voters\n",
    "        print(include.sum(), \"/\", X.shape[0], \"points remain\")\n",
    "        results[i, 0] = idx[0]\n",
    "        results[i, 1] = idx[1]\n",
    "        results[i, 2] = idx[2]\n",
    "        results[i, 3] = val\n",
    "        \n",
    "    return results\n",
    "\n",
    "def find_clusters_bins_cpu(bins, hough, n=10):\n",
    "    results = np.full((n, 4), -1)\n",
    "    include = np.full(bins.shape[1], True)\n",
    "    for i in range(n):\n",
    "        idx, val = hough_max_cpu(hough)\n",
    "        print(\"cluster has value\", val, \"at\", idx)\n",
    "        voters = find_voters_bins_cpu(\n",
    "            hough, bins, directions.b, *idx\n",
    "        )\n",
    "        vote_bins_cpu(\n",
    "            hough, bins[:, include & voters], directions.b, -1\n",
    "        )\n",
    "        include &= ~voters # exclude voters\n",
    "        print(include.sum(), \"/\", X.shape[0], \"points remain\")\n",
    "        results[i, 0] = idx[0]\n",
    "        results[i, 1] = idx[1]\n",
    "        results[i, 2] = idx[2]\n",
    "        results[i, 3] = val\n",
    "        \n",
    "    return results\n",
    "\n",
    "def search_cpu(X, directions, dx, reference_time, num_results=10, precompute=False):\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    x_min, x_max, y_min, y_max = projected_bounds_cpu(X, directions.b, reference_time)\n",
    "    \n",
    "    num_dir = directions.b.shape[0]\n",
    "    _dx = dx.to(u.deg).value\n",
    "    _dy = _dx\n",
    "    num_x = int((x_max - x_min) / _dx  + 1)\n",
    "    num_y = int((y_max - y_min) / _dy  + 1)\n",
    "\n",
    "    hough = np.zeros((num_dir, num_x, num_y), dtype=np.uint32)    \n",
    "\n",
    "    num_dir, num_x, num_y = hough.shape\n",
    "    \n",
    "    if precompute:\n",
    "        bins = make_bins_cpu(X, directions.b, min_x, min_y, _dx, _dy, reference_time)\n",
    "        print(bins.shape)\n",
    "        vote_bins_cpu(hough, bins, directions.b, 1)\n",
    "        results = find_clusters_bins_cpu(bins, hough, n=num_results)\n",
    "    else:\n",
    "        vote_points_cpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time, 1)\n",
    "        results = find_clusters_points_cpu(X, hough, n=num_results)\n",
    "    \n",
    "    return results\n",
    "        \n",
    "# min_x, max_x, min_y, max_y = projected_bounds_cpu(X, directions.b, ref_time)\n",
    "\n",
    "# num_dir = directions.b.shape[0]\n",
    "# _dx = dx.to(u.deg).value\n",
    "# _dy = _dx\n",
    "# num_x = int((max_x - min_x) / _dx  + 1)\n",
    "# num_y = int((max_y - min_y) / _dy  + 1)\n",
    "\n",
    "# hough = np.zeros((num_dir, num_x, num_y), dtype=np.int32)\n",
    "\n",
    "# vote_points_cpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time, 1)\n",
    "# h = hough.copy()\n",
    "# results = find_clusters_cpu(h, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "225dd5de-4a74-40af-abec-dd410cc3ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster has value 101 at (2085, 155, 79)\n",
      "9017 / 9118 points remain\n",
      "cluster has value 99 at (2580, 130, 64)\n",
      "8918 / 9118 points remain\n",
      "cluster has value 99 at (2710, 171, 50)\n",
      "8819 / 9118 points remain\n",
      "cluster has value 99 at (2712, 70, 95)\n",
      "8720 / 9118 points remain\n",
      "cluster has value 96 at (2778, 146, 68)\n",
      "8624 / 9118 points remain\n",
      "cluster has value 94 at (2645, 86, 88)\n",
      "8530 / 9118 points remain\n",
      "cluster has value 91 at (2578, 139, 96)\n",
      "8439 / 9118 points remain\n",
      "cluster has value 90 at (2456, 151, 60)\n",
      "8349 / 9118 points remain\n",
      "cluster has value 84 at (2642, 136, 67)\n",
      "8265 / 9118 points remain\n",
      "cluster has value 75 at (2779, 111, 84)\n",
      "8190 / 9118 points remain\n",
      "CPU times: user 3.57 s, sys: 65.4 ms, total: 3.64 s\n",
      "Wall time: 4.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2085,  155,   79,  101],\n",
       "       [2580,  130,   64,   99],\n",
       "       [2710,  171,   50,   99],\n",
       "       [2712,   70,   95,   99],\n",
       "       [2778,  146,   68,   96],\n",
       "       [2645,   86,   88,   94],\n",
       "       [2578,  139,   96,   91],\n",
       "       [2456,  151,   60,   90],\n",
       "       [2642,  136,   67,   84],\n",
       "       [2779,  111,   84,   75]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search_cpu(X, directions, dx, ref_time, num_results=10, precompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2611c3e0-d4b3-4605-8e8c-4bce41b79e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4848, 9118, 2)\n",
      "cluster has value 101 at (2085, 155, 79)\n",
      "9017 / 9118 points remain\n",
      "cluster has value 99 at (2580, 130, 64)\n",
      "8918 / 9118 points remain\n",
      "cluster has value 99 at (2710, 171, 50)\n",
      "8819 / 9118 points remain\n",
      "cluster has value 99 at (2712, 70, 95)\n",
      "8720 / 9118 points remain\n",
      "cluster has value 96 at (2778, 146, 68)\n",
      "8624 / 9118 points remain\n",
      "cluster has value 94 at (2645, 86, 88)\n",
      "8530 / 9118 points remain\n",
      "cluster has value 91 at (2578, 139, 96)\n",
      "8439 / 9118 points remain\n",
      "cluster has value 90 at (2456, 151, 60)\n",
      "8349 / 9118 points remain\n",
      "cluster has value 84 at (2642, 136, 67)\n",
      "8265 / 9118 points remain\n",
      "cluster has value 75 at (2779, 111, 84)\n",
      "8190 / 9118 points remain\n",
      "CPU times: user 3.35 s, sys: 115 ms, total: 3.47 s\n",
      "Wall time: 3.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2085,  155,   79,  101],\n",
       "       [2580,  130,   64,   99],\n",
       "       [2710,  171,   50,   99],\n",
       "       [2712,   70,   95,   99],\n",
       "       [2778,  146,   68,   96],\n",
       "       [2645,   86,   88,   94],\n",
       "       [2578,  139,   96,   91],\n",
       "       [2456,  151,   60,   90],\n",
       "       [2642,  136,   67,   84],\n",
       "       [2779,  111,   84,   75]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search_cpu(X, directions, dx, ref_time, num_results=10, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e07d9f-c579-4466-857b-b3058a2c6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:salad.hough:next cluster has value 101 at (2085, 155, 79)\n",
    "# INFO:salad.hough:9017 points remain\n",
    "# INFO:salad.hough:next cluster has value 99 at (2580, 130, 64)\n",
    "# INFO:salad.hough:8918 points remain\n",
    "# INFO:salad.hough:next cluster has value 99 at (2710, 171, 50)\n",
    "# INFO:salad.hough:8819 points remain\n",
    "# INFO:salad.hough:next cluster has value 99 at (2712, 70, 95)\n",
    "# INFO:salad.hough:8720 points remain\n",
    "# INFO:salad.hough:next cluster has value 96 at (2778, 146, 68)\n",
    "# INFO:salad.hough:8624 points remain\n",
    "# INFO:salad.hough:next cluster has value 94 at (2645, 86, 88)\n",
    "# INFO:salad.hough:8530 points remain\n",
    "# INFO:salad.hough:next cluster has value 91 at (2578, 139, 96)\n",
    "# INFO:salad.hough:8439 points remain\n",
    "# INFO:salad.hough:next cluster has value 90 at (2456, 151, 60)\n",
    "# INFO:salad.hough:8349 points remain\n",
    "# INFO:salad.hough:next cluster has value 84 at (2642, 136, 67)\n",
    "# INFO:salad.hough:8265 points remain\n",
    "# INFO:salad.hough:next cluster has value 75 at (2779, 111, 84)\n",
    "# INFO:salad.hough:8190 points remain\n",
    "# INFO:salad.hough:next cluster has value 61 at (3672, 71, 30)\n",
    "# INFO:salad.hough:8129 points remain\n",
    "# INFO:salad.hough:next cluster has value 44 at (2710, 82, 35)\n",
    "# INFO:salad.hough:8085 points remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b6c26-2c23-4494-9e69-574d7b5bcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[1330,  124,   63,  101],\n",
    "       [1667,  137,   40,   99],\n",
    "       [1722,   56,   76,   99],\n",
    "       [1668,  104,   51,   98],\n",
    "       [1670,  103,   51,   97],\n",
    "       [1774,  117,   54,   96],\n",
    "       [1720,  137,   40,   95],\n",
    "       [1722,   69,   70,   95],\n",
    "       [1570,  120,   48,   92],\n",
    "       [1616,  111,   77,   91]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b120bf6b-18a7-4e98-8606-b9c0e05b5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 747 ms, total: 2.88 s\n",
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((2085, 155, 79), 101),\n",
       " ((2580, 130, 64), 99),\n",
       " ((2710, 171, 50), 99),\n",
       " ((2712, 70, 95), 99),\n",
       " ((2644, 171, 50), 97),\n",
       " ((2778, 146, 68), 96),\n",
       " ((2645, 86, 88), 94),\n",
       " ((2578, 139, 96), 91),\n",
       " ((2456, 151, 60), 90),\n",
       " ((2579, 139, 96), 90)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "min_x, max_x, min_y, max_y = projected_bounds_gpu(X, directions.b, ref_time)\n",
    "\n",
    "num_dir = directions.b.shape[0]\n",
    "_dx = dx.to(u.deg).value\n",
    "_dy = _dx\n",
    "num_x = int((max_x - min_x) / _dx  + 1)\n",
    "num_y = int((max_y - min_y) / _dy  + 1)\n",
    "\n",
    "hough = np.zeros((num_dir, num_x, num_y), dtype=np.uint32)\n",
    "\n",
    "hough = vote_points_gpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time)\n",
    "find_clusters_gpu(hough, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e08c43a-fa5c-4466-92e3-b83481617a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 226 ms, sys: 74.9 ms, total: 301 ms\n",
      "Wall time: 299 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2085, 155, 79), 101)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "min_x, max_x, min_y, max_y = projected_bounds_gpu(X, directions.b, ref_time)\n",
    "\n",
    "num_dir = directions.b.shape[0]\n",
    "_dx = dx.to(u.deg).value\n",
    "_dy = _dx\n",
    "num_x = int((max_x - min_x) / _dx  + 1)\n",
    "num_y = int((max_y - min_y) / _dy  + 1)\n",
    "\n",
    "hough = np.zeros((num_dir, num_x, num_y), dtype=np.uint32)\n",
    "hough = vote_points_gpu(hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time)\n",
    "hough_max_gpu(hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9328198c-cb98-4ccb-a538-a614a25fd5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 ms, sys: 886 µs, total: 17.3 ms\n",
      "Wall time: 15.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1330, 124, 63), 101)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hough_max_cpu(hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5770bce1-1836-4f0b-badf-35bd11bab8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hough2 = vote_points_gpu(\n",
    "    hough, X, directions.b, min_x, min_y, _dx, _dy, ref_time,\n",
    "    coef=-1,\n",
    "    mask_dir=1330, mask_x=124, mask_y=63\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d49f65fc-e439-477b-a759-7cee0015c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2067712e-9036-4c3c-aa68-0f1dc9171992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote with mask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074a9d27-7d77-4a5a-a864-5bb2e1bfc4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229076"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply.reduce(hough.shape) // 256 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5056a2d7-b437-4562-bd82-eac9a1999feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 170, 112)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "201e918b-7cee-4868-aae9-96f53813e51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "382af6a0-d957-44c9-903b-c34988641832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 ms, sys: 21 µs, total: 19.4 ms\n",
      "Wall time: 17.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1330, 124, 63)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.unravel_index(hough.argmax(), hough.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c2ca3ab-f1f1-4746-9ccf-5e618b663e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 ms, sys: 7.95 ms, total: 29.5 ms\n",
      "Wall time: 28.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1664, 108, 53), 100.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hough_argmax_gpu(hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc4391e1-e3b0-4b38-8538-156789b91b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.6 ms, sys: 906 µs, total: 81.5 ms\n",
      "Wall time: 79.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1330,  124,   63], dtype=int32), 202.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hough_argmax_cpu(hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "718911e8-a30a-4917-a338-8b64e2641b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118580 (385, 22, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 0, 0), 1.867356296054e-312)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def find_local_hough_max(hough, local_max_vals, local_max_idxs):\n",
    "    \"\"\"\n",
    "    Step 1: Each CUDA block finds its local maximum value and index.\n",
    "    \"\"\"\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    x_idx = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    y_idx = cuda.blockIdx.z * cuda.blockDim.z + cuda.threadIdx.z\n",
    "\n",
    "    # Ensure thread is in valid bounds\n",
    "    if dir_idx < hough.shape[0] and x_idx < hough.shape[1] and y_idx < hough.shape[2]:\n",
    "        val = hough[dir_idx, x_idx, y_idx]\n",
    "        block_id = cuda.blockIdx.x + cuda.blockIdx.y * cuda.gridDim.x + cuda.blockIdx.z * cuda.gridDim.x * cuda.gridDim.y\n",
    "\n",
    "        # Use atomic operations to find block-wise maximum\n",
    "        cuda.atomic.max(local_max_vals, block_id, val)\n",
    "\n",
    "        if local_max_vals[block_id] == val:  # Ensure correct index\n",
    "            local_max_idxs[block_id, 0] = dir_idx\n",
    "            local_max_idxs[block_id, 1] = x_idx\n",
    "            local_max_idxs[block_id, 2] = y_idx\n",
    "\n",
    "@cuda.jit\n",
    "def find_global_hough_max(local_max_vals, local_max_idxs, max_val, max_idx):\n",
    "    \"\"\"\n",
    "    Step 2: Find the global maximum value and index.\n",
    "    \"\"\"\n",
    "    thread_id = cuda.threadIdx.x\n",
    "    num_blocks = local_max_vals.shape[0]\n",
    "\n",
    "    # Shared memory for block-wide reduction\n",
    "    shared_max_val = cuda.shared.array(1, numba.float64)\n",
    "    shared_max_idx = cuda.shared.array(3, numba.int32)\n",
    "\n",
    "    # Initialize shared memory\n",
    "    if thread_id == 0:\n",
    "        shared_max_val[0] = -np.inf\n",
    "        shared_max_idx[0] = -1\n",
    "        shared_max_idx[1] = -1\n",
    "        shared_max_idx[2] = -1\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Load thread data\n",
    "    if thread_id < num_blocks:\n",
    "        val = local_max_vals[thread_id]\n",
    "        if val > shared_max_val[0]:\n",
    "            shared_max_val[0] = val\n",
    "            shared_max_idx[0] = local_max_idxs[thread_id, 0]\n",
    "            shared_max_idx[1] = local_max_idxs[thread_id, 1]\n",
    "            shared_max_idx[2] = local_max_idxs[thread_id, 2]\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Final max update by thread 0\n",
    "    if thread_id == 0:\n",
    "        max_val[0] = shared_max_val[0]\n",
    "        max_idx[0] = shared_max_idx[0]\n",
    "        max_idx[1] = shared_max_idx[1]\n",
    "        max_idx[2] = shared_max_idx[2]\n",
    "\n",
    "def find_hough_max(hough: np.ndarray):\n",
    "    \"\"\"\n",
    "    Wrapper function to execute the two-pass reduction on the GPU.\n",
    "    \"\"\"\n",
    "    d_hough = cuda.to_device(hough)\n",
    "\n",
    "    # Determine grid and block sizes\n",
    "    threads_per_block = (8, 8, 8)\n",
    "    blocks_per_grid = (\n",
    "        (hough.shape[0] + threads_per_block[0] - 1) // threads_per_block[0],\n",
    "        (hough.shape[1] + threads_per_block[1] - 1) // threads_per_block[1],\n",
    "        (hough.shape[2] + threads_per_block[2] - 1) // threads_per_block[2],\n",
    "    )\n",
    "    num_blocks = blocks_per_grid[0] * blocks_per_grid[1] * blocks_per_grid[2]\n",
    "    print(num_blocks, blocks_per_grid)\n",
    "\n",
    "    # Allocate device memory for local maxima\n",
    "    d_local_max_vals = cuda.device_array(num_blocks, dtype=np.float64)\n",
    "    d_local_max_idxs = cuda.device_array((num_blocks, 3), dtype=np.int32)\n",
    "\n",
    "    # Step 1: Find per-block maxima\n",
    "    find_local_hough_max[blocks_per_grid, threads_per_block](d_hough, d_local_max_vals, d_local_max_idxs)\n",
    "\n",
    "    # Allocate device memory for final reduction\n",
    "    d_max_val = cuda.device_array(1, dtype=np.float64)\n",
    "    d_max_idx = cuda.device_array(3, dtype=np.int32)\n",
    "\n",
    "    # Initialize max_val to -inf before reduction\n",
    "    d_max_val[:] = -np.inf\n",
    "\n",
    "    # Step 2: Find the global maximum (use enough threads)\n",
    "    threads_final_reduction = min(1024, num_blocks)\n",
    "    find_global_hough_max[1, threads_final_reduction](d_local_max_vals, d_local_max_idxs, d_max_val, d_max_idx)\n",
    "\n",
    "    # Copy results back\n",
    "    max_idx = d_max_idx.copy_to_host()\n",
    "    max_val = d_max_val.copy_to_host()\n",
    "\n",
    "    return tuple(max_idx), max_val[0]\n",
    "\n",
    "find_hough_max(hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfc073fc-bd34-4f6b-bf26-175a60e2e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7, 3, 7), 294)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def find_local_hough_max(hough, local_max_vals, local_max_idxs):\n",
    "    \"\"\"\n",
    "    Step 1: Each CUDA block finds its local maximum value and index.\n",
    "    \"\"\"\n",
    "    dir_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    x_idx = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    y_idx = cuda.blockIdx.z * cuda.blockDim.z + cuda.threadIdx.z\n",
    "\n",
    "    # Ensure thread is in valid bounds\n",
    "    if dir_idx >= hough.shape[0] or x_idx >= hough.shape[1] or y_idx >= hough.shape[2]:\n",
    "        return  \n",
    "\n",
    "    val = hough[dir_idx, x_idx, y_idx]\n",
    "    block_id = cuda.blockIdx.x + cuda.blockIdx.y * cuda.gridDim.x + cuda.blockIdx.z * cuda.gridDim.x * cuda.gridDim.y\n",
    "\n",
    "    # Use atomic operations to find block-wise maximum\n",
    "    cuda.atomic.max(local_max_vals, block_id, val)\n",
    "\n",
    "    if local_max_vals[block_id] == val:  # Ensure correct index\n",
    "        local_max_idxs[block_id, 0] = dir_idx\n",
    "        local_max_idxs[block_id, 1] = x_idx\n",
    "        local_max_idxs[block_id, 2] = y_idx\n",
    "\n",
    "@cuda.jit\n",
    "def reduce_max(local_max_vals, local_max_idxs, reduced_max_vals, reduced_max_idxs):\n",
    "    \"\"\"\n",
    "    Multi-pass reduction: Reduce max values and indices.\n",
    "    \"\"\"\n",
    "    thread_id = cuda.grid(1)\n",
    "    num_threads = cuda.gridsize(1)\n",
    "\n",
    "    # Grid-stride loop to handle arbitrary sizes\n",
    "    max_val = -np.inf\n",
    "    max_idx = (-1, -1, -1)\n",
    "\n",
    "    for i in range(thread_id, local_max_vals.shape[0], num_threads):\n",
    "        if local_max_vals[i] > max_val:\n",
    "            max_val = local_max_vals[i]\n",
    "            max_idx = (local_max_idxs[i, 0], local_max_idxs[i, 1], local_max_idxs[i, 2])\n",
    "\n",
    "    # Store results\n",
    "    if thread_id < reduced_max_vals.shape[0]:\n",
    "        reduced_max_vals[thread_id] = max_val\n",
    "        reduced_max_idxs[thread_id, 0] = max_idx[0]\n",
    "        reduced_max_idxs[thread_id, 1] = max_idx[1]\n",
    "        reduced_max_idxs[thread_id, 2] = max_idx[2]\n",
    "\n",
    "def find_hough_max(hough: np.ndarray):\n",
    "    \"\"\"\n",
    "    Wrapper function for multi-pass reduction.\n",
    "    \"\"\"\n",
    "    d_hough = cuda.to_device(hough)\n",
    "\n",
    "    # Determine grid and block sizes\n",
    "    threads_per_block = (8, 8, 8)\n",
    "    blocks_per_grid = (\n",
    "        (hough.shape[0] + threads_per_block[0] - 1) // threads_per_block[0],\n",
    "        (hough.shape[1] + threads_per_block[1] - 1) // threads_per_block[1],\n",
    "        (hough.shape[2] + threads_per_block[2] - 1) // threads_per_block[2],\n",
    "    )\n",
    "    num_blocks = blocks_per_grid[0] * blocks_per_grid[1] * blocks_per_grid[2]\n",
    "    \n",
    "    # Allocate device memory for local maxima\n",
    "    d_local_max_vals = cuda.device_array(num_blocks, dtype=np.int32)\n",
    "    d_local_max_idxs = cuda.device_array((num_blocks, 3), dtype=np.int32)\n",
    "\n",
    "    # Step 1: Find per-block maxima\n",
    "    find_local_hough_max[blocks_per_grid, threads_per_block](d_hough, d_local_max_vals, d_local_max_idxs)\n",
    "\n",
    "    # Multi-pass reduction\n",
    "    while num_blocks > 1:\n",
    "        num_threads = min(1024, num_blocks)\n",
    "        num_blocks = (num_blocks + num_threads - 1) // num_threads  # Reduce further\n",
    "        \n",
    "        d_reduced_max_vals = cuda.device_array(num_blocks, dtype=np.int32)\n",
    "        d_reduced_max_idxs = cuda.device_array((num_blocks, 3), dtype=np.int32)\n",
    "\n",
    "        reduce_max[num_blocks, num_threads](d_local_max_vals, d_local_max_idxs, d_reduced_max_vals, d_reduced_max_idxs)\n",
    "\n",
    "        # Swap buffers for next reduction step\n",
    "        d_local_max_vals = d_reduced_max_vals\n",
    "        d_local_max_idxs = d_reduced_max_idxs\n",
    "\n",
    "    # Copy results back\n",
    "    max_idx = d_local_max_idxs.copy_to_host()[0]\n",
    "    max_val = d_local_max_vals.copy_to_host()[0]\n",
    "\n",
    "    return tuple(max_idx), max_val\n",
    "\n",
    "arr = (100 * np.random.randn(1000).reshape(10, 10, 10)).astype(int)\n",
    "\n",
    "find_hough_max(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d35a52-da74-4fd5-b8b1-73ea60edfa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:numba.cuda.cudadrv.driver:Call to cuMemAlloc results in UNKNOWN_CUDA_ERROR\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuMemAlloc results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)  \u001b[38;5;66;03m# Larger array size for testing\u001b[39;00m\n\u001b[1;32m    100\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m*\u001b[39mshape)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 101\u001b[0m d_arr \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m threads_per_block \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m    104\u001b[0m blocks_per_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((s \u001b[38;5;241m+\u001b[39m t \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m t \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shape, threads_per_block))\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devices.py:232\u001b[0m, in \u001b[0;36mrequire_context.<locals>._require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_require_cuda_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _runtime\u001b[38;5;241m.\u001b[39mensure_context():\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/api.py:128\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(obj, stream, copy, to)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"to_device(obj, stream=0, copy=True, to=None)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mAllocate and transfer a numpy ndarray or structured scalar to the device.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    hary = d_ary.copy_to_host(stream=stream)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     to, new \u001b[38;5;241m=\u001b[39m \u001b[43mdevicearray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43muser_explicit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:876\u001b[0m, in \u001b[0;36mauto_device\u001b[0;34m(obj, stream, copy, user_explicit)\u001b[0m\n\u001b[1;32m    871\u001b[0m     obj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    872\u001b[0m         obj,\n\u001b[1;32m    873\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    874\u001b[0m         subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    875\u001b[0m     sentry_contiguous(obj)\n\u001b[0;32m--> 876\u001b[0m     devobj \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_array_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mCUDA_WARN_ON_IMPLICIT_COPY:\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:797\u001b[0m, in \u001b[0;36mfrom_array_like\u001b[0;34m(ary, stream, gpu_data)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array_like\u001b[39m(ary, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, gpu_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a DeviceNDArray object that is like ary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDeviceNDArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mgpu_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:103\u001b[0m, in \u001b[0;36mDeviceNDArrayBase.__init__\u001b[0;34m(self, shape, strides, dtype, stream, gpu_data)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malloc_size \u001b[38;5;241m=\u001b[39m _driver\u001b[38;5;241m.\u001b[39mmemory_size_from_info(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 103\u001b[0m     gpu_data \u001b[38;5;241m=\u001b[39m \u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemalloc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malloc_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malloc_size \u001b[38;5;241m=\u001b[39m _driver\u001b[38;5;241m.\u001b[39mdevice_memory_size(gpu_data)\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:1372\u001b[0m, in \u001b[0;36mContext.memalloc\u001b[0;34m(self, bytesize)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmemalloc\u001b[39m(\u001b[38;5;28mself\u001b[39m, bytesize):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemalloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytesize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:1064\u001b[0m, in \u001b[0;36mNumbaCUDAMemoryManager.memalloc\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallocator\u001b[39m():\n\u001b[1;32m   1062\u001b[0m         driver\u001b[38;5;241m.\u001b[39mcuMemAlloc(byref(ptr), size)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attempt_allocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallocator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     alloc_key \u001b[38;5;241m=\u001b[39m ptr\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m   1067\u001b[0m finalizer \u001b[38;5;241m=\u001b[39m _alloc_finalizer(\u001b[38;5;28mself\u001b[39m, ptr, alloc_key, size)\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:851\u001b[0m, in \u001b[0;36mHostOnlyCUDAMemoryManager._attempt_allocation\u001b[0;34m(self, allocator)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03mAttempt allocation by calling *allocator*.  If an out-of-memory error\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03mis raised, the pending deallocations are flushed and the allocation\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03mis retried.  If it fails in the second attempt, the error is reraised.\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mallocator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CudaAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# is out-of-memory?\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_NV_BINDING:\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:1062\u001b[0m, in \u001b[0;36mNumbaCUDAMemoryManager.memalloc.<locals>.allocator\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallocator\u001b[39m():\n\u001b[0;32m-> 1062\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemAlloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:327\u001b[0m, in \u001b[0;36mDriver._ctypes_wrap_fn.<locals>.safe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall driver api: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, libfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    326\u001b[0m retcode \u001b[38;5;241m=\u001b[39m libfn(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_ctypes_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:395\u001b[0m, in \u001b[0;36mDriver._check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mCUDA_ERROR_NOT_INITIALIZED:\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_fork()\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m CudaAPIError(retcode, msg)\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuMemAlloc results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def block_max_3d(arr, block_max_vals, block_max_idxs):\n",
    "    \"\"\"\n",
    "    Kernel to compute the maximum value and its index within each block.\n",
    "    \"\"\"\n",
    "    tx, ty, tz = cuda.threadIdx.x, cuda.threadIdx.y, cuda.threadIdx.z\n",
    "    bx, by, bz = cuda.blockIdx.x, cuda.blockIdx.y, cuda.blockIdx.z\n",
    "    bdx, bdy, bdz = cuda.blockDim.x, cuda.blockDim.y, cuda.blockDim.z\n",
    "    \n",
    "    # Compute global index\n",
    "    x, y, z = bx * bdx + tx, by * bdy + ty, bz * bdz + tz\n",
    "    \n",
    "    tid = tx + ty * bdx + tz * (bdx * bdy)\n",
    "    \n",
    "    # Dynamically allocate shared memory\n",
    "    shared_max_val = cuda.shared.array(shape=(256,), dtype=numba.float32)\n",
    "    shared_max_idx = cuda.shared.array(shape=(256, 3), dtype=numba.int32)\n",
    "    \n",
    "    if tid < 256:\n",
    "        shared_max_val[tid] = -np.inf\n",
    "        shared_max_idx[tid, 0] = -1\n",
    "        shared_max_idx[tid, 1] = -1\n",
    "        shared_max_idx[tid, 2] = -1\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Load data and perform local reduction\n",
    "    if x < arr.shape[0] and y < arr.shape[1] and z < arr.shape[2]:\n",
    "        val = arr[x, y, z]\n",
    "        shared_max_val[tid] = val\n",
    "        shared_max_idx[tid, 0] = x\n",
    "        shared_max_idx[tid, 1] = y\n",
    "        shared_max_idx[tid, 2] = z\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Perform block-level reduction\n",
    "    stride = 128\n",
    "    while stride > 0:\n",
    "        if tid < stride and tid + stride < 256:\n",
    "            if shared_max_val[tid + stride] > shared_max_val[tid]:\n",
    "                shared_max_val[tid] = shared_max_val[tid + stride]\n",
    "                shared_max_idx[tid, 0] = shared_max_idx[tid + stride, 0]\n",
    "                shared_max_idx[tid, 1] = shared_max_idx[tid + stride, 1]\n",
    "                shared_max_idx[tid, 2] = shared_max_idx[tid + stride, 2]\n",
    "        cuda.syncthreads()\n",
    "        stride //= 2\n",
    "    \n",
    "    # Store block maximums to global memory\n",
    "    if tid == 0:\n",
    "        block_idx = bx + by * cuda.gridDim.x + bz * cuda.gridDim.x * cuda.gridDim.y\n",
    "        block_max_vals[block_idx] = shared_max_val[0]\n",
    "        block_max_idxs[block_idx, 0] = shared_max_idx[0, 0]\n",
    "        block_max_idxs[block_idx, 1] = shared_max_idx[0, 1]\n",
    "        block_max_idxs[block_idx, 2] = shared_max_idx[0, 2]\n",
    "\n",
    "@cuda.jit\n",
    "def final_max_reduce(block_max_vals, block_max_idxs, max_val, max_idx):\n",
    "    \"\"\"\n",
    "    Kernel to find the global maximum from the block-level maximums.\n",
    "    \"\"\"\n",
    "    tid = cuda.threadIdx.x\n",
    "    \n",
    "    # Dynamically allocate shared memory\n",
    "    shared_max_val = cuda.shared.array(shape=(256,), dtype=numba.float32)\n",
    "    shared_max_idx = cuda.shared.array(shape=(256, 3), dtype=numba.int32)\n",
    "    \n",
    "    if tid < block_max_vals.shape[0]:\n",
    "        shared_max_val[tid] = block_max_vals[tid]\n",
    "        shared_max_idx[tid, 0] = block_max_idxs[tid, 0]\n",
    "        shared_max_idx[tid, 1] = block_max_idxs[tid, 1]\n",
    "        shared_max_idx[tid, 2] = block_max_idxs[tid, 2]\n",
    "    else:\n",
    "        shared_max_val[tid] = -np.inf\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Perform reduction within a single block\n",
    "    stride = block_max_vals.shape[0] // 2\n",
    "    while stride > 0:\n",
    "        if tid < stride:\n",
    "            if shared_max_val[tid + stride] > shared_max_val[tid]:\n",
    "                shared_max_val[tid] = shared_max_val[tid + stride]\n",
    "                shared_max_idx[tid, 0] = shared_max_idx[tid + stride, 0]\n",
    "                shared_max_idx[tid, 1] = shared_max_idx[tid + stride, 1]\n",
    "                shared_max_idx[tid, 2] = shared_max_idx[tid + stride, 2]\n",
    "        cuda.syncthreads()\n",
    "        stride //= 2\n",
    "    \n",
    "    # Store result to global memory\n",
    "    if tid == 0:\n",
    "        max_val[0] = shared_max_val[0]\n",
    "        max_idx[0], max_idx[1], max_idx[2] = shared_max_idx[0, 0], shared_max_idx[0, 1], shared_max_idx[0, 2]\n",
    "\n",
    "# Example Usage\n",
    "shape = (256, 256, 256)  # Larger array size for testing\n",
    "arr = np.random.rand(*shape).astype(np.float32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "threads_per_block = (8, 8, 8)\n",
    "blocks_per_grid = tuple((s + t - 1) // t for s, t in zip(shape, threads_per_block))\n",
    "num_blocks = blocks_per_grid[0] * blocks_per_grid[1] * blocks_per_grid[2]\n",
    "\n",
    "d_block_max_vals = cuda.device_array(num_blocks, dtype=np.float32)\n",
    "d_block_max_idxs = cuda.device_array((num_blocks, 3), dtype=np.int32)\n",
    "d_max_val = cuda.device_array(1, dtype=np.float32)\n",
    "d_max_idx = cuda.device_array(3, dtype=np.int32)\n",
    "\n",
    "# First pass: Block-level maximums\n",
    "block_max_3d[blocks_per_grid, threads_per_block](d_arr, d_block_max_vals, d_block_max_idxs)\n",
    "\n",
    "# Second pass: Global maximum reduction\n",
    "final_max_reduce[1, min(256, num_blocks)](d_block_max_vals, d_block_max_idxs, d_max_val, d_max_idx)\n",
    "\n",
    "# Synchronize and check for errors\n",
    "cuda.synchronize()\n",
    "print(cuda.get_last_error())\n",
    "\n",
    "# Copy results to host\n",
    "max_val = d_max_val.copy_to_host()\n",
    "max_idx = d_max_idx.copy_to_host()\n",
    "\n",
    "print(\"Max Value:\", max_val[0], \"==\", arr.max())\n",
    "print(\"Max Index:\", tuple(max_idx), \"==\", np.unravel_index(arr.argmax(), arr.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1adaa-5501-4405-ba5d-1b5f6a7ef242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f7394a6-7c3e-4602-9ca8-ed5b0a41781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:numba.cuda.cudadrv.driver:Call to cuMemGetInfo results in UNKNOWN_CUDA_ERROR\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuMemGetInfo results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda\n\u001b[0;32m----> 3\u001b[0m free_mem, total_mem \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memory_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFree Memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfree_mem\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB, Total Memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_mem\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:1263\u001b[0m, in \u001b[0;36mContext.get_memory_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memory_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns (free, total) memory in bytes in the context.\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memory_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:1079\u001b[0m, in \u001b[0;36mNumbaCUDAMemoryManager.get_memory_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m free \u001b[38;5;241m=\u001b[39m c_size_t()\n\u001b[1;32m   1078\u001b[0m total \u001b[38;5;241m=\u001b[39m c_size_t()\n\u001b[0;32m-> 1079\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemGetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m free \u001b[38;5;241m=\u001b[39m free\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m   1081\u001b[0m total \u001b[38;5;241m=\u001b[39m total\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:327\u001b[0m, in \u001b[0;36mDriver._ctypes_wrap_fn.<locals>.safe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall driver api: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, libfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    326\u001b[0m retcode \u001b[38;5;241m=\u001b[39m libfn(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_ctypes_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:395\u001b[0m, in \u001b[0;36mDriver._check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mCUDA_ERROR_NOT_INITIALIZED:\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_fork()\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m CudaAPIError(retcode, msg)\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuMemGetInfo results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "free_mem, total_mem = cuda.current_context().get_memory_info()\n",
    "print(f\"Free Memory: {free_mem / 1e6} MB, Total Memory: {total_mem / 1e6} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eac057fe-8510-4fd5-a7c4-283232105ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar  7 00:26:47 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:21:00.0  On |                  N/A |\n",
      "| 39%   51C    P2              64W / 260W |    669MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:48:00.0 Off |                  N/A |\n",
      "| 26%   29C    P8              14W / 260W |      4MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2352      G   /usr/bin/X                                   39MiB |\n",
      "|    0   N/A  N/A      2977      G   /usr/bin/gnome-shell                         14MiB |\n",
      "|    0   N/A  N/A      8682      C   python                                      204MiB |\n",
      "|    0   N/A  N/A     36702      C   .../miniconda3/envs/booknlp/bin/python      406MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c01c452-3c94-4c9c-8579-d62c70e7777a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "728fbd07-afc1-49b7-89f6-baa4e31fa15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8) (385, 22, 14)\n",
      "(3080, 170, 112)\n",
      "Max Value: 0\n",
      "Max Index: (-1, -1, -1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def max_3d_array(arr, max_val, max_idx):\n",
    "    tx, ty, tz = cuda.grid(3)\n",
    "    \n",
    "    # Initialize shared memory for local maximum values and indices\n",
    "    shared_max_val = cuda.shared.array(shape=(1,), dtype=numba.int32)\n",
    "    shared_max_idx = cuda.shared.array(shape=(3,), dtype=numba.int32)\n",
    "    \n",
    "    if tx == 0 and ty == 0 and tz == 0:\n",
    "        shared_max_val[0] = -np.inf\n",
    "        shared_max_idx[0] = -1\n",
    "        shared_max_idx[1] = -1\n",
    "        shared_max_idx[2] = -1\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    if tx < arr.shape[0] and ty < arr.shape[1] and tz < arr.shape[2]:\n",
    "        val = arr[tx, ty, tz]\n",
    "        \n",
    "        # Use atomic operation for thread safety\n",
    "        prev = cuda.atomic.max(shared_max_val, 0, val)\n",
    "        if val > prev:\n",
    "            shared_max_val = val\n",
    "            shared_max_idx[0] = tx\n",
    "            shared_max_idx[1] = ty\n",
    "            shared_max_idx[2] = tz\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Store result to global memory by a single thread\n",
    "    if tx == 0 and ty == 0 and tz == 0:\n",
    "        max_val[0] = shared_max_val[0]\n",
    "        max_idx[0] = shared_max_idx[0]\n",
    "        max_idx[1] = shared_max_idx[1]\n",
    "        max_idx[2] = shared_max_idx[2]\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# shape = hough.shape\n",
    "# shape = (120, 120, 120)\n",
    "# arr = np.random.rand(*shape).astype(hough.dtype)\n",
    "\n",
    "shape = hough.shape\n",
    "arr = hough\n",
    "d_max_val = cuda.device_array(1, dtype=np.int32)\n",
    "d_max_idx = cuda.device_array(3, dtype=np.int32)\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "threads_per_block = (8, 8, 8)\n",
    "blocks_per_grid = tuple((s + t - 1) // t for s, t in zip(shape, threads_per_block))\n",
    "print(threads_per_block, blocks_per_grid)\n",
    "print(arr.shape)\n",
    "\n",
    "max_3d_array[blocks_per_grid, threads_per_block](d_arr, d_max_val, d_max_idx)\n",
    "\n",
    "max_val = d_max_val.copy_to_host()\n",
    "max_idx = d_max_idx.copy_to_host()\n",
    "print(\"Max Value:\", max_val[0])\n",
    "print(\"Max Index:\", tuple(max_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a315af7-0715-42d3-80e7-5377b9919e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def cmax(result, array):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2239941d-b0c9-460b-87dc-2a28c5ee2f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 == 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/users/stevengs/opt_lsst/conda/envs/lsst-scipipe-8.0.0/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m max_example_3d[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m16\u001b[39m](result, arr)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(arr))\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(result[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(arr))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def max_example_3d(result, values):\n",
    "    \"\"\"\n",
    "    Find the maximum value in values and store in result[0].\n",
    "    Both result and values are 3d arrays.\n",
    "    \"\"\"\n",
    "    i, j, k = cuda.grid(3)\n",
    "    # Atomically store to result[0,1,2] from values[i, j, k]\n",
    "    cuda.atomic.max(result, (0, 1, 2), values[i, j, k])\n",
    "\n",
    "shape = hough.shape\n",
    "arr = hough\n",
    "# arr = np.random.rand(np.multiply.reduce(shape)).reshape(shape)\n",
    "result = np.zeros((3, 3, 3), dtype=arr.dtype)\n",
    "max_example_3d[128, 16](result, arr)\n",
    "print(result[0, 1, 2], \"==\", np.max(arr))\n",
    "assert(result[0, 1, 2] == np.max(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0ccacba-f5a9-4e4c-84cf-8dfd7309932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 170, 112)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ae3a97a0-34a4-4b6e-8a46-811b052ac339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Value: 707\n",
      "Max Index: (1330, 124, 63)\n"
     ]
    }
   ],
   "source": [
    "idx = np.unravel_index(arr.argmax(), arr.shape)\n",
    "val = arr[idx]\n",
    "print(\"Max Value:\", val)\n",
    "print(\"Max Index:\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fc7a031f-0a14-4918-9a54-f877d3d2d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c03bf9-b54d-4c0c-8f5a-5af702d1d8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SALAD",
   "language": "python",
   "name": "salad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
